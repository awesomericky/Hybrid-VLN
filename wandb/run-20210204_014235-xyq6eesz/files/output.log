Training on train env ...
Epoch: [1][1/1]	Time 14.092 (14.092)	Loss 26.1724 (26.1724)	
Evaluating on val_seen env ...
Epoch: [1][1/64]	Time 2.352 (2.352)	Loss 2.7847 (2.7847)	
Epoch: [1][2/64]	Time 1.871 (2.111)	Loss 2.7432 (2.7640)	
Epoch: [1][3/64]	Time 2.802 (2.342)	Loss 3.4904 (3.0061)	
Epoch: [1][4/64]	Time 2.042 (2.267)	Loss 3.0788 (3.0243)	
Epoch: [1][5/64]	Time 3.575 (2.528)	Loss 4.5578 (3.3310)	
Epoch: [1][6/64]	Time 2.762 (2.567)	Loss 4.7801 (3.5725)	
Epoch: [1][7/64]	Time 2.405 (2.544)	Loss 4.1054 (3.6486)	
Epoch: [1][8/64]	Time 2.261 (2.509)	Loss 3.2416 (3.5977)	
Epoch: [1][9/64]	Time 1.492 (2.396)	Loss 2.3388 (3.4579)	
Epoch: [1][10/64]	Time 2.439 (2.400)	Loss 3.6403 (3.4761)	
Epoch: [1][11/64]	Time 2.579 (2.416)	Loss 3.3878 (3.4681)	
Epoch: [1][12/64]	Time 1.529 (2.342)	Loss 2.0866 (3.3530)	
Epoch: [1][13/64]	Time 2.008 (2.317)	Loss 2.9753 (3.3239)	
Epoch: [1][14/64]	Time 3.118 (2.374)	Loss 5.7544 (3.4975)	
Epoch: [1][15/64]	Time 2.247 (2.366)	Loss 4.0730 (3.5359)	
Epoch: [1][16/64]	Time 1.837 (2.333)	Loss 2.5916 (3.4769)	
Epoch: [1][17/64]	Time 1.084 (2.259)	Loss 2.0882 (3.3952)	
Epoch: [1][18/64]	Time 2.085 (2.249)	Loss 3.0140 (3.3740)	
Epoch: [1][19/64]	Time 2.373 (2.256)	Loss 3.9499 (3.4043)	
Epoch: [1][20/64]	Time 2.018 (2.244)	Loss 3.1411 (3.3911)	
Epoch: [1][21/64]	Time 1.369 (2.202)	Loss 2.6181 (3.3543)	
Epoch: [1][22/64]	Time 1.097 (2.152)	Loss 1.9015 (3.2883)	
Epoch: [1][23/64]	Time 2.496 (2.167)	Loss 4.6585 (3.3479)	
Epoch: [1][24/64]	Time 1.878 (2.155)	Loss 3.9644 (3.3736)	
Epoch: [1][25/64]	Time 2.059 (2.151)	Loss 4.3682 (3.4133)	
Epoch: [1][26/64]	Time 1.989 (2.145)	Loss 3.6929 (3.4241)	
Epoch: [1][27/64]	Time 1.656 (2.127)	Loss 2.8303 (3.4021)	
Epoch: [1][28/64]	Time 1.607 (2.108)	Loss 3.1339 (3.3925)	
Epoch: [1][29/64]	Time 1.502 (2.087)	Loss 2.7781 (3.3713)	
Epoch: [1][30/64]	Time 2.289 (2.094)	Loss 3.7743 (3.3848)	
Epoch: [1][31/64]	Time 1.966 (2.090)	Loss 4.1405 (3.4091)	
Epoch: [1][32/64]	Time 1.637 (2.076)	Loss 3.0764 (3.3987)	
Epoch: [1][33/64]	Time 1.439 (2.057)	Loss 3.1688 (3.3918)	
Epoch: [1][34/64]	Time 1.095 (2.028)	Loss 1.9742 (3.3501)	
Epoch: [1][35/64]	Time 2.414 (2.039)	Loss 4.6878 (3.3883)	
Epoch: [1][36/64]	Time 1.026 (2.011)	Loss 2.0866 (3.3521)	
Epoch: [1][37/64]	Time 2.103 (2.014)	Loss 4.1985 (3.3750)	
Epoch: [1][38/64]	Time 2.044 (2.014)	Loss 4.1602 (3.3957)	
Epoch: [1][39/64]	Time 1.996 (2.014)	Loss 3.9743 (3.4105)	
Epoch: [1][40/64]	Time 1.322 (1.997)	Loss 2.7816 (3.3948)	
Epoch: [1][41/64]	Time 0.469 (1.959)	Loss 1.3676 (3.3454)	
Epoch: [1][42/64]	Time 0.927 (1.935)	Loss 2.2205 (3.3186)	
Epoch: [1][43/64]	Time 1.772 (1.931)	Loss 3.6202 (3.3256)	
Epoch: [1][44/64]	Time 2.159 (1.936)	Loss 4.7150 (3.3572)	
Epoch: [1][45/64]	Time 1.883 (1.935)	Loss 4.1817 (3.3755)	
Epoch: [1][46/64]	Time 1.011 (1.915)	Loss 2.0739 (3.3472)	
Epoch: [1][47/64]	Time 1.371 (1.903)	Loss 3.4297 (3.3489)	
Epoch: [1][48/64]	Time 1.303 (1.891)	Loss 3.2453 (3.3468)	
Epoch: [1][49/64]	Time 1.444 (1.882)	Loss 2.8711 (3.3371)	
Epoch: [1][50/64]	Time 1.728 (1.879)	Loss 4.0439 (3.3512)	
Epoch: [1][51/64]	Time 1.748 (1.876)	Loss 4.2164 (3.3682)	
Epoch: [1][52/64]	Time 0.938 (1.858)	Loss 2.2158 (3.3460)	
Epoch: [1][53/64]	Time 1.834 (1.858)	Loss 4.2023 (3.3622)	
Epoch: [1][54/64]	Time 1.796 (1.856)	Loss 3.7147 (3.3687)	
Epoch: [1][55/64]	Time 2.661 (1.871)	Loss 6.0188 (3.4169)	
Epoch: [1][56/64]	Time 1.756 (1.869)	Loss 4.0053 (3.4274)	
Epoch: [1][57/64]	Time 0.876 (1.852)	Loss 2.0423 (3.4031)	
Epoch: [1][58/64]	Time 0.878 (1.835)	Loss 2.2274 (3.3828)	
Epoch: [1][59/64]	Time 1.739 (1.833)	Loss 4.3380 (3.3990)	
Epoch: [1][60/64]	Time 1.291 (1.824)	Loss 3.1654 (3.3951)	
Epoch: [1][61/64]	Time 0.889 (1.809)	Loss 2.3463 (3.3779)	
Epoch: [1][62/64]	Time 0.884 (1.794)	Loss 2.2393 (3.3596)	
Epoch: [1][63/64]	Time 1.338 (1.787)	Loss 3.0063 (3.3540)	
Epoch: [1][64/64]	Time 0.930 (1.773)	Loss 2.0545 (3.3336)	
Traceback (most recent call last):
  File "tasks/R2R/main.py", line 340, in <module>
    main(opts)
  File "tasks/R2R/main.py", line 310, in main
    success_rate.append(trainer.eval(epoch, val_env, tb_logger))
  File "/disk2/yunhokim/Hybrid-VLN/tasks/R2R/trainer.py", line 242, in eval
    self.agent.write_results()
  File "/disk2/yunhokim/Hybrid-VLN/tasks/R2R/agents/pano_agent.py", line 40, in write_results
    with open(self.results_path, 'w') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'tasks/R2R-pano/results/hybrid-agent_val_seen_epoch_1.json'
